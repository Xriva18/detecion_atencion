# üß† Monitor de Atenci√≥n y Generaci√≥n Educativa con IA

> Plataforma educativa inteligente que detecta el nivel de atenci√≥n del estudiante en tiempo real mediante Computer Vision y genera evaluaciones personalizadas utilizando IA Generativa.

---

## üìã Descripci√≥n del Proyecto

Este sistema est√° dise√±ado para mejorar el proceso de aprendizaje h√≠brido/remoto. Utiliza la c√°mara web del estudiante para monitorear m√©tricas de atenci√≥n (parpadeo, postura de la cabeza, mirada) mientras consume contenido educativo.

Al finalizar la lecci√≥n, el sistema procesa el video, genera una transcripci√≥n autom√°tica y crea un **Cuestionario Adaptativo** utilizando Inteligencia Artificial. La dificultad del cuestionario se ajusta din√°micamente seg√∫n el puntaje de atenci√≥n promedio detectado durante la sesi√≥n.

## üöÄ Caracter√≠sticas Principales

### üëÅÔ∏è Detecci√≥n de Aternci√≥n (Computer Vision)
- **Motor**: MediaPipe Face Mesh.
- **M√©tricas**:
    - **EAR (Eye Aspect Ratio)**: Detecta somnolencia y parpadeo frecuente.
    - **Head Pose Estimation**: Detecta si el estudiante mira fuera de la pantalla (Pitch, Yaw, Roll).
- **Procesamiento**: Websockets de alta velocidad para an√°lisis frame a frame en tiempo real sin latencia perceptible.

### ü§ñ Inteligencia Artificial Generativa
- **Transcripci√≥n de Video**: Implementaci√≥n local de **OpenAI Whisper** (Modelo Base) procesando videos en segundo plano.
- **Generaci√≥n de Contenido**: Integraci√≥n con **Google Gemini 2.5 Flash** para actuar como un "Profesor Experto" y generar preguntas de examen basadas exclusivamente en la transcripci√≥n.
- **Personalizaci√≥n**:
    - Atenci√≥n Baja -> Preguntas de Memoria/Simples.
    - Atenci√≥n Media -> Preguntas de Comprensi√≥n.
    - Atenci√≥n Alta -> Preguntas de An√°lisis/Desafiantes.

### üìπ Gesti√≥n de Video
- **Soporte H√≠brido**:
    - Carga de archivos locales (`.mp4`).
    - Descarga y transcripci√≥n autom√°tica de enlaces de **YouTube**.
    - Integraci√≥n con base de datos de videos (Supabase Storage).
- **Robustez**: L√≥gica de reintentos y fallback autom√°tico (Whisper) si la IA generativa falla por sobrecarga.

---

## üõ†Ô∏è Stack Tecnol√≥gico

### Backend (API & Procesamiento)
- **Lenguaje**: Python 3.11+
- **Framework**: **FastAPI** (Async, WebSockets, BackgroundTasks).
- **IA/ML**:
    - `mediapipe` (Visi√≥n Computacional).
    - `openai-whisper` (Speech-to-Text).
    - `google-genai` (LLM SDK).
    - `ffmpeg-python` (Procesamiento de audio/video).
- **Base de Datos**: Supabase (PostgreSQL) via `supabase-py`.

### Frontend (Interfaz de Usuario)
- **Framework**: **Next.js 14** (React, TypeScript).
- **Estilos**: TailwindCSS (UI Moderna y Oscura).
- **Comunicaci√≥n**: Axios (REST) y API nativa de WebSockets.
- **Multimedia**: Canvas HTML5 para dibujo de malla facial en tiempo real.

---

## üèóÔ∏è Arquitectura del Sistema

```mermaid
graph TD
    User[Estudiante] -->|Webcam Video| FE[Frontend Next.js]
    FE -->|WebSocket Stream| BEC[Backend Computer Vision]
    BEC -->|Analiza Frames| MP[MediaPipe]
    MP -->|Atenci√≥n Score| DB[(Supabase)]
    
    User -->|Sube Video/Link| FE
    FE -->|POST Video| BEI[Backend IA Service]
    BEI -->|Background Task| WP[Whisper Local]
    WP -->|Transcripci√≥n| GEM[Gemini 2.5 Flash]
    GEM -->|Quiz JSON| FE
    
    subgraph "Backend FastAPI"
        BEC
        BEI
        MP
        WP
    end
    
    subgraph "Cloud Services"
        GEM
        DB
    end
```

---

## üì¶ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos
- Python 3.10 o superior.
- Node.js 18 o superior.
- Clave de API de Google Gemini (`GEMINI_API_KEY`).
- Credenciales de Supabase (`SUPABASE_URL`, `SUPABASE_KEY`).

### 1. Backend Setup
```bash
cd backend
# Instalar dependencias
pip install -r requirements.txt

# Ejecutar script de instalaci√≥n de FFmpeg (Windows)
powershell -ExecutionPolicy Bypass -File install_ffmpeg.ps1

# Iniciar Servidor
./restart_backend.bat
# O manualmente: uvicorn main:app --reload --port 8000
```

### 2. Frontend Setup
```bash
cd frontend
# Instalar dependencias
npm install --legacy-peer-deps

# Iniciar Desarrollo
npm run dev
```

---

## üí° Gu√≠a de Uso R√°pido

1.  **Detecci√≥n de Atenci√≥n**:
    - Navega a `/parpadeo` para probar la detecci√≥n aislada.
    - Mueve la cabeza o cierra los ojos para ver c√≥mo cambian los indicadores.

2.  **Prueba de IA (Generaci√≥n de Quiz)**:
    - Ve a `/test-gemini`.
    - **Sube un video** corto o selecciona uno de la lista.
    - Observa el proceso: *Subiendo -> Transcribiendo -> Analizando*.
    - Revisa la transcripci√≥n y el quiz generado abajo.

3.  **Flujo Completo**:
    - Inicia sesi√≥n como estudiante.
    - Entra a una clase y selecciona un video.
    - Asegura que la c√°mara est√© activa.
    - Al finalizar el video, el sistema calcular√° tu atenci√≥n promedio y te redirigir√° a un examen personalizado.

---

## üìÇ Estructura de Directorios Clave

```
/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ bin/                  # Binarios locales (ffmpeg)
‚îÇ   ‚îú‚îÄ‚îÄ endpoints/            # Rutas de API (Transcribe, GenAI, Detect)
‚îÇ   ‚îú‚îÄ‚îÄ services/             # L√≥gica de Negocio (AIService, TranscriptionService, BlinkService)
‚îÇ   ‚îú‚îÄ‚îÄ utils/                # Utilidades de imagen y helpers
‚îÇ   ‚îî‚îÄ‚îÄ main.py              # Entry point FastAPI
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ app/                  # Rutas Next.js (test-gemini, parpadeo, estudiante)
‚îÇ   ‚îú‚îÄ‚îÄ components/           # Componentes React (VideoPlayer, Camera)
‚îÇ   ‚îî‚îÄ‚îÄ public/               # Assets est√°ticos
‚îÇ
‚îî‚îÄ‚îÄ README.md                 # Documentaci√≥n del Proyecto
```

> **Nota**: Este proyecto est√° optimizado para funcionar en entornos locales de Windows, aprovechando aceleraci√≥n por GPU si est√° disponible para MediaPipe y Whisper (aunque Whisper est√° configurado en 'base' para compatibilidad CPU).
